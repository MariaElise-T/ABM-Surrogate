{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f6fcac-b8c5-4a38-b3b1-d7bf430321a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"  \n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')  # No GUI calls\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541a4e28-6baa-4296-9048-61619dbbf0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6115c6c-bbe6-4dee-b26d-ae5172f910bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8348a347-aa55-4878-920b-cbe6f0654a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = pd.read_csv(\"C:/Users/met48/Desktop/TS-Clustering/SimData/epsteinCV_outputs_active.csv\", header=None)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_output_scaled = scaler.fit_transform(data_output)\n",
    "data_output = pd.DataFrame(data_output_scaled)\n",
    "\n",
    "# --- Load the conditioning input parameters ---\n",
    "data_input = pd.read_csv(\"C:/Users/met48/Desktop/TS-Clustering/SimData/epsteinCV_inputs.csv\", sep=\" \", header=None)\n",
    "\n",
    "# --- Combine input + output ---\n",
    "data = pd.concat([data_input, data_output], axis=1)\n",
    "\n",
    "# --- Sample to 1280 examples if needed ---\n",
    "data = data.sample(n=20000, random_state=1)\n",
    "\n",
    "# --- Split into training and validation sets ---\n",
    "train_data_pd, valid_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Extract tensors for training ---\n",
    "train_inputs = torch.tensor(train_data_pd.iloc[:, :3].values, dtype=torch.float32)\n",
    "train_outputs = torch.tensor(train_data_pd.iloc[:, 3:].values, dtype=torch.float32)\n",
    "\n",
    "valid_inputs = torch.tensor(valid_data.iloc[:, :3].values, dtype=torch.float32)\n",
    "valid_outputs = torch.tensor(valid_data.iloc[:, 3:].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c1d1ab-0d28-42f5-9513-c2a756e705de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30239</th>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.106032</td>\n",
       "      <td>0.315410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13381</th>\n",
       "      <td>0.926782</td>\n",
       "      <td>0.043385</td>\n",
       "      <td>0.473899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314955</td>\n",
       "      <td>0.543763</td>\n",
       "      <td>0.549276</td>\n",
       "      <td>0.508615</td>\n",
       "      <td>0.462440</td>\n",
       "      <td>0.407994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.019297</td>\n",
       "      <td>0.019297</td>\n",
       "      <td>0.021365</td>\n",
       "      <td>0.033081</td>\n",
       "      <td>0.042040</td>\n",
       "      <td>0.026878</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>0.023432</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29424</th>\n",
       "      <td>0.913186</td>\n",
       "      <td>0.080047</td>\n",
       "      <td>0.554347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068229</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>0.799078</td>\n",
       "      <td>0.043411</td>\n",
       "      <td>0.749577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.003446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24564</th>\n",
       "      <td>0.508585</td>\n",
       "      <td>0.216760</td>\n",
       "      <td>0.014888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14786</th>\n",
       "      <td>0.961642</td>\n",
       "      <td>0.029016</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661613</td>\n",
       "      <td>0.796692</td>\n",
       "      <td>0.774638</td>\n",
       "      <td>0.747071</td>\n",
       "      <td>0.717436</td>\n",
       "      <td>0.694693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361819</td>\n",
       "      <td>0.363198</td>\n",
       "      <td>0.359063</td>\n",
       "      <td>0.353549</td>\n",
       "      <td>0.345968</td>\n",
       "      <td>0.343901</td>\n",
       "      <td>0.345279</td>\n",
       "      <td>0.345279</td>\n",
       "      <td>0.339766</td>\n",
       "      <td>0.353549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27630</th>\n",
       "      <td>0.703353</td>\n",
       "      <td>0.023680</td>\n",
       "      <td>0.021124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543763</td>\n",
       "      <td>0.603722</td>\n",
       "      <td>0.589938</td>\n",
       "      <td>0.564438</td>\n",
       "      <td>0.535493</td>\n",
       "      <td>0.511371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175052</td>\n",
       "      <td>0.175052</td>\n",
       "      <td>0.173673</td>\n",
       "      <td>0.161957</td>\n",
       "      <td>0.161957</td>\n",
       "      <td>0.164025</td>\n",
       "      <td>0.160579</td>\n",
       "      <td>0.151620</td>\n",
       "      <td>0.146795</td>\n",
       "      <td>0.141282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13438</th>\n",
       "      <td>0.516617</td>\n",
       "      <td>0.349011</td>\n",
       "      <td>0.731921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19696</th>\n",
       "      <td>0.582633</td>\n",
       "      <td>0.302842</td>\n",
       "      <td>0.718413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35618</th>\n",
       "      <td>0.819184</td>\n",
       "      <td>0.049808</td>\n",
       "      <td>0.772430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2    0         1         2         3    \\\n",
       "30239  0.721832  0.106032  0.315410  0.0  0.088904  0.000000  0.000000   \n",
       "13381  0.926782  0.043385  0.473899  0.0  0.314955  0.543763  0.549276   \n",
       "29424  0.913186  0.080047  0.554347  0.0  0.068229  0.004824  0.000689   \n",
       "3624   0.799078  0.043411  0.749577  0.0  0.013784  0.000689  0.002068   \n",
       "24564  0.508585  0.216760  0.014888  0.0  0.034459  0.000000  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "14786  0.961642  0.029016  0.278000  0.0  0.661613  0.796692  0.774638   \n",
       "27630  0.703353  0.023680  0.021124  0.0  0.543763  0.603722  0.589938   \n",
       "13438  0.516617  0.349011  0.731921  0.0  0.002068  0.000000  0.000000   \n",
       "19696  0.582633  0.302842  0.718413  0.0  0.002068  0.000000  0.000000   \n",
       "35618  0.819184  0.049808  0.772430  0.0  0.002068  0.000000  0.000000   \n",
       "\n",
       "            4         5         6    ...       242       243       244  \\\n",
       "30239  0.001378  0.000689  0.000000  ...  0.000000  0.000689  0.000689   \n",
       "13381  0.508615  0.462440  0.407994  ...  0.013784  0.019297  0.019297   \n",
       "29424  0.000000  0.000689  0.000000  ...  0.000000  0.000689  0.000689   \n",
       "3624   0.001378  0.000689  0.000000  ...  0.017919  0.010338  0.008270   \n",
       "24564  0.000000  0.000689  0.000000  ...  0.001378  0.000000  0.000689   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "14786  0.747071  0.717436  0.694693  ...  0.361819  0.363198  0.359063   \n",
       "27630  0.564438  0.535493  0.511371  ...  0.175052  0.175052  0.173673   \n",
       "13438  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "19696  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "35618  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "            245       246       247       248       249       250       251  \n",
       "30239  0.002757  0.002757  0.002068  0.000689  0.000689  0.002068  0.002757  \n",
       "13381  0.021365  0.033081  0.042040  0.026878  0.027567  0.023432  0.025500  \n",
       "29424  0.001378  0.000000  0.001378  0.004135  0.001378  0.000689  0.000689  \n",
       "3624   0.002757  0.000000  0.000689  0.000689  0.001378  0.001378  0.003446  \n",
       "24564  0.000000  0.000000  0.000689  0.000000  0.001378  0.000689  0.000689  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "14786  0.353549  0.345968  0.343901  0.345279  0.345279  0.339766  0.353549  \n",
       "27630  0.161957  0.161957  0.164025  0.160579  0.151620  0.146795  0.141282  \n",
       "13438  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "19696  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "35618  0.000000  0.000689  0.000689  0.000689  0.000000  0.000689  0.000000  \n",
       "\n",
       "[20000 rows x 255 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3d2653-d8de-4ff9-a17b-815477be9a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbed96ae-04e8-475c-b95f-6216e57c463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1adc2d4ffd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e44a0c93-ae06-43e4-841c-ac3a4ef3e3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16000, 255])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_length = train_inputs.shape[0]\n",
    "train_data = torch.from_numpy(train_data_pd.values).float().to('cpu')\n",
    "train_labels = torch.zeros(train_data_length)\n",
    "train_set = [\n",
    "    (train_data[i], train_labels[i]) for i in range(train_data_length)\n",
    "]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4220fa0-c934-4e78-abde-0af11bc95061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ConditionalTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, time_series_data, condition_data):\n",
    "        \"\"\"\n",
    "        time_series_data: Tensor of shape (N, 252)\n",
    "        condition_data: Tensor of shape (N, 3)\n",
    "        \"\"\"\n",
    "        self.time_series_data = time_series_data\n",
    "        self.condition_data = condition_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_series_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.time_series_data[idx], self.condition_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac87b346-e5c2-40fb-ab11-439889956f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = ConditionalTimeSeriesDataset(train_outputs, train_inputs)\n",
    "valid_dataset = ConditionalTimeSeriesDataset(valid_outputs, valid_inputs)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4638888-fd16-4f12-b76d-e7e104c94124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim=252, condition_dim=3):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim + condition_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, conditions):\n",
    "        # Concatenate time series and condition\n",
    "        x = torch.cat([x, conditions], dim=1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4914f9de-edaa-4d95-b0be-de36c4cd4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = ConditionalDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b5fce61-cd8c-48e6-b95a-324a704ad266",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, condition_dim=3, output_len=252, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(latent_dim + condition_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.output_proj = nn.Linear(hidden_dim, 1)\n",
    "        self.output_len = output_len\n",
    "\n",
    "    def forward(self, z, conditions):\n",
    "        batch_size = z.size(0)\n",
    "        x = torch.cat([z, conditions], dim=1)\n",
    "        x = self.input_proj(x)  # (B, H)\n",
    "\n",
    "        # Repeat across time steps\n",
    "        x = x.unsqueeze(1).repeat(1, self.output_len, 1)  # (B, T, H)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.output_proj(lstm_out).squeeze(-1)  # (B, T)\n",
    "        return out\n",
    "\n",
    "generator = ConditionalGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac4fb663-00dc-454b-88b8-2cab222c256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 300\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f97b0a7-fe46-4afb-84a7-d37fd9b9d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb0111-defd-4e0e-8da1-105b25efe908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Step: 0 Loss D.: 0.6944021582603455\n",
      "Epoch: 0 Step: 0 Loss G.: 0.7369272708892822\n",
      "Epoch: 0 Step: 100 Loss D.: 0.2651016116142273\n",
      "Epoch: 0 Step: 100 Loss G.: 1.610642910003662\n",
      "Epoch: 0 Step: 200 Loss D.: 0.21237897872924805\n",
      "Epoch: 0 Step: 200 Loss G.: 2.838747262954712\n",
      "Epoch: 0 Step: 300 Loss D.: 0.3313138484954834\n",
      "Epoch: 0 Step: 300 Loss G.: 2.0783228874206543\n",
      "Epoch: 0 Step: 400 Loss D.: 0.3305582106113434\n",
      "Epoch: 0 Step: 400 Loss G.: 2.8780431747436523\n",
      "Epoch: 25 Step: 0 Loss D.: 0.46152371168136597\n",
      "Epoch: 25 Step: 0 Loss G.: 1.3781428337097168\n",
      "Epoch: 25 Step: 100 Loss D.: 0.6416344046592712\n",
      "Epoch: 25 Step: 100 Loss G.: 1.0354175567626953\n",
      "Epoch: 25 Step: 200 Loss D.: 0.5932410955429077\n",
      "Epoch: 25 Step: 200 Loss G.: 1.1954452991485596\n",
      "Epoch: 25 Step: 300 Loss D.: 0.5336039066314697\n",
      "Epoch: 25 Step: 300 Loss G.: 1.112735390663147\n",
      "Epoch: 25 Step: 400 Loss D.: 0.5231232643127441\n",
      "Epoch: 25 Step: 400 Loss G.: 1.1205263137817383\n",
      "Epoch: 50 Step: 0 Loss D.: 0.587220311164856\n",
      "Epoch: 50 Step: 0 Loss G.: 0.7711024284362793\n",
      "Epoch: 50 Step: 100 Loss D.: 0.5390349626541138\n",
      "Epoch: 50 Step: 100 Loss G.: 1.0319597721099854\n",
      "Epoch: 50 Step: 200 Loss D.: 0.9964812397956848\n",
      "Epoch: 50 Step: 200 Loss G.: 0.8561270833015442\n",
      "Epoch: 50 Step: 300 Loss D.: 0.551466703414917\n",
      "Epoch: 50 Step: 300 Loss G.: 1.1396063566207886\n",
      "Epoch: 50 Step: 400 Loss D.: 0.7155463099479675\n",
      "Epoch: 50 Step: 400 Loss G.: 0.9305496215820312\n"
     ]
    }
   ],
   "source": [
    "losses_discriminator = []\n",
    "losses_generator = []\n",
    "steps = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n, (real_samples, condition_vectors) in enumerate(train_loader):\n",
    "        # real_samples: (batch_size, 252)\n",
    "        # condition_vectors: (batch_size, 3)\n",
    "\n",
    "        real_samples_labels = torch.ones((batch_size, 1))\n",
    "        generated_samples_labels = torch.zeros((batch_size, 1))\n",
    "\n",
    "        # Sample latent space\n",
    "        latent_dim = 100\n",
    "        latent_space_samples = torch.randn((batch_size, latent_dim))  # Latent space dimension\n",
    "\n",
    "        # Ensure condition_vectors has the same batch size as latent_space_samples\n",
    "        condition_vectors = condition_vectors.expand(batch_size, -1)  # Repeat condition vectors to match batch size\n",
    "\n",
    "        # === Generator step ===\n",
    "        # Pass latent_space_samples and condition_vectors separately to the generator\n",
    "        generated_samples = generator(latent_space_samples, condition_vectors)\n",
    "\n",
    "        # === Prepare discriminator input ===\n",
    "        all_samples = torch.cat((real_samples, generated_samples.detach()), dim=0)\n",
    "        all_conditions = torch.cat((condition_vectors, condition_vectors), dim=0)  # Duplicate for both real and generated\n",
    "        all_labels = torch.cat((real_samples_labels, generated_samples_labels), dim=0)\n",
    "\n",
    "        # === Train discriminator ===\n",
    "        discriminator.zero_grad()\n",
    "        output_discriminator = discriminator(all_samples, all_conditions)\n",
    "        loss_discriminator = loss_function(output_discriminator, all_labels)\n",
    "        loss_discriminator.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        # === Train generator ===\n",
    "        generator.zero_grad()\n",
    "        # Generate again to avoid using detached samples\n",
    "        generated_samples = generator(latent_space_samples, condition_vectors)\n",
    "        output_discriminator_generated = discriminator(generated_samples, condition_vectors)\n",
    "        loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "        loss_generator.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        # === Logging (every 100 iterations per epoch) ===\n",
    "        if n % 100 == 0 and epoch % 25 == 0:  # Adjust this number to control how often you log\n",
    "            losses_discriminator.append(loss_discriminator.item())\n",
    "            losses_generator.append(loss_generator.item())\n",
    "            steps.append(epoch * len(train_loader) + n)\n",
    "            print(f\"Epoch: {epoch} Step: {n} Loss D.: {loss_discriminator.item()}\")\n",
    "            print(f\"Epoch: {epoch} Step: {n} Loss G.: {loss_generator.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0829d9-2d79-4193-84ab-a36cb20cc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, losses_discriminator, label='Discriminator Loss')\n",
    "plt.plot(steps, losses_generator, label='Generator Loss')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Discriminator and Generator Loss During Training')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc02b0-edeb-426b-9b58-3cf2a55ef984",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), \"generator_gan_ecv_lstm.pth\")\n",
    "torch.save(discriminator.state_dict(), \"discriminator_gan_ecv_lstm.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb35f08-ccbd-4db9-b798-8051bdef5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Pick N random examples from your validation set\n",
    "n_samples = 100\n",
    "indices = random.sample(range(len(valid_dataset)), n_samples)\n",
    "\n",
    "real_samples = []\n",
    "real_conditions = []\n",
    "\n",
    "for idx in indices:\n",
    "    real_ts, condition = valid_dataset[idx]\n",
    "    real_samples.append(real_ts)\n",
    "    real_conditions.append(condition)\n",
    "\n",
    "real_samples = torch.stack(real_samples)           # (n_samples, 252)\n",
    "real_conditions = torch.stack(real_conditions)     # (n_samples, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83e6a3-8e4e-420c-a382-1e6962827313",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    latent_dim = 100  # or whatever your latent size is\n",
    "    z = torch.randn(n_samples, latent_dim)\n",
    "    generated_samples = generator(z, real_conditions)  # (n_samples, 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415a1d4-4b67-4fae-9aba-16b134272ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94642e2c-e4b4-428b-857c-0921b33b2aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the global min and max for both real and generated samples\n",
    "min_val = min(real_samples.min(), generated_samples.min())\n",
    "max_val = max(real_samples.max(), generated_samples.max())\n",
    "\n",
    "# Assuming real_samples, generated_samples, and real_conditions are already in the correct shape\n",
    "\n",
    "for i in range(n_samples):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(real_samples[i].cpu().numpy(), label=\"Real\", linewidth=2)\n",
    "    plt.plot(generated_samples[i].cpu().numpy(), label=\"Generated\", linestyle=\"--\")\n",
    "    \n",
    "    # Set the axis limits based on global min and max\n",
    "    plt.xlim(0, len(real_samples[i]))  # Standardize x-axis (if you know your x range)\n",
    "    plt.ylim(min_val, max_val)  # Standardize y-axis\n",
    "\n",
    "    plt.title(f\"Comparison for Condition: {real_conditions[i].cpu().numpy()}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffaf1f-66bf-4dbc-b37d-9c4db188deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_gan(real_samples, generated_samples):\n",
    "\n",
    "    # convert list to numpy arrays\n",
    "    predicted_values = generated_samples.cpu().numpy()  # [N, 255, 1]\n",
    "    true_values = real_samples.cpu().numpy()            # [N, 255, 1]\n",
    "\n",
    "    # flatten for metrics\n",
    "    y_pred_flat = predicted_values.flatten()\n",
    "    y_true_flat = true_values.flatten()\n",
    "    \n",
    "    # compute evaluation metrics\n",
    "    mse = mean_squared_error(y_true_flat, y_pred_flat)\n",
    "    mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "    r2 = r2_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "    print(f\"Validation MSE: {mse:.6f}\")\n",
    "    print(f\"Validation MAE: {mae:.6f}\")\n",
    "    print(f\"Validation R² Score: {r2:.6f}\")\n",
    "\n",
    "    return mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fb68b-407f-4ffc-9a2b-f4d04910a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "evaluate_model_gan(real_samples, generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da7886-17e3-41f8-a6db-995a5f92336b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2734165-6f62-4121-93bb-c89820531ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torchenv)",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
