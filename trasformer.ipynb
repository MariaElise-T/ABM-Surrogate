{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "siboVxRJ5pes"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization tools\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.X = torch.tensor(dataframe.iloc[:, :3].values, dtype=torch.float32)  # Input: [Batch, 3]\n",
    "        self.Y = torch.tensor(dataframe.iloc[:, 3:].values, dtype=torch.float32).unsqueeze(-1) # Output: [Batch, 255, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding for Time Steps\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# Transformer Model\n",
    "class TransformerTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, seq_length, d_model, nhead, num_layers, dim_feedforward):\n",
    "        super(TransformerTimeSeriesModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    " \n",
    "        # Input Encoder (maps input to d_model size)\n",
    "        self.encoder = nn.Linear(input_dim, d_model)  # (Batch, 3) -> (Batch, d_model)\n",
    "        \n",
    "        # Project input to match the sequence length\n",
    "        self.expand_input = nn.Linear(d_model, seq_length * d_model)  # (Batch, d_model) -> (Batch, seq_length * d_model)\n",
    "        \n",
    "        # Target embedding for decoder input\n",
    "        self.target_embedding = nn.Linear(1, d_model)  # New embedding layer for target sequence\n",
    "  \n",
    "        # Positional Encoding for Time Steps\n",
    "        self.pos_encoder = PositionalEncoding(d_model, seq_length)\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Final Output Layer\n",
    "        self.output_layer = nn.Linear(d_model, output_dim)  # (Batch, 255, d_model) -> (Batch, 255, 1)\n",
    "\n",
    "    def forward(self, x, target_seq):\n",
    "        # x: Input features [Batch, 3]\n",
    "        # target_seq: Target sequence for teacher forcing [Batch, 255, 1]\n",
    "        \n",
    "        # Encode input features\n",
    "        encoded_input = self.encoder(x)  # [Batch, d_model]\n",
    "        \n",
    "        # Expand input to match sequence length\n",
    "        expanded_input = self.expand_input(encoded_input)  # [Batch, seq_length * d_model]\n",
    "        expanded_input = expanded_input.view(-1, self.seq_length, self.d_model)  # Reshape to [Batch, 255, d_model]\n",
    "        \n",
    "        # Add Positional Encoding\n",
    "        expanded_input = self.pos_encoder(expanded_input)\n",
    "        \n",
    "        # Process the target sequence through the same encoding pipeline\n",
    "  #      target_embeddings = self.encoder(target_seq)\n",
    "  #      target_embeddings = nn.Linear(1, d_model)(target_seq)  # [Batch, 255, d_model]\n",
    "        target_embeddings = self.target_embedding(target_seq)  # [Batch, 255, d_model]\n",
    "        target_embeddings = self.pos_encoder(target_embeddings)\n",
    "        \n",
    "        # Decode sequence\n",
    "        output = self.transformer_decoder(\n",
    "            tgt=target_embeddings, memory=expanded_input\n",
    "        )  # Output shape: [Batch, 255, d_model]\n",
    "        \n",
    "        # Map to output dimensions\n",
    "        predictions = self.output_layer(output)  # [Batch, 255, 1]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_fn, num_epochs, device):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in dataloader:\n",
    "            x, y = batch  # x: [Batch, N], y: [Batch, T]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Prepare target for teacher forcing\n",
    "            target_seq = y \n",
    "            #target_seq = y[:, :-1]  # All except last time step\n",
    "            #actual = y[:, 1:]       # All except first time step\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(x, target_seq)\n",
    "            loss = loss_fn(output, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "data_input = pd.read_csv(\"C:/Users/met48/Desktop/TS-Clustering/SimData/epsteinCV_inputs.csv\", sep=\" \", header=None)\n",
    "data_output = pd.read_csv(\"C:/Users/met48/Desktop/TS-Clustering/SimData/epsteinCV_outputs_active.csv\", header=None)\n",
    "data = pd.concat([data_input, data_output], axis=1)\n",
    "# Split the data into training and validation sets\n",
    "train_data, valid_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the validation set to a new CSV file\n",
    "valid_data.to_csv(\"validation_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>0.776554</td>\n",
       "      <td>0.054693</td>\n",
       "      <td>0.033034</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "      <td>694</td>\n",
       "      <td>600</td>\n",
       "      <td>495</td>\n",
       "      <td>382</td>\n",
       "      <td>287</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34861</th>\n",
       "      <td>0.982732</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>0.216774</td>\n",
       "      <td>0</td>\n",
       "      <td>1085</td>\n",
       "      <td>1238</td>\n",
       "      <td>1215</td>\n",
       "      <td>1196</td>\n",
       "      <td>1171</td>\n",
       "      <td>1154</td>\n",
       "      <td>...</td>\n",
       "      <td>846</td>\n",
       "      <td>841</td>\n",
       "      <td>858</td>\n",
       "      <td>864</td>\n",
       "      <td>863</td>\n",
       "      <td>853</td>\n",
       "      <td>861</td>\n",
       "      <td>862</td>\n",
       "      <td>855</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18274</th>\n",
       "      <td>0.974610</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>0.495488</td>\n",
       "      <td>0</td>\n",
       "      <td>877</td>\n",
       "      <td>1122</td>\n",
       "      <td>1104</td>\n",
       "      <td>1080</td>\n",
       "      <td>1051</td>\n",
       "      <td>1033</td>\n",
       "      <td>...</td>\n",
       "      <td>716</td>\n",
       "      <td>712</td>\n",
       "      <td>718</td>\n",
       "      <td>719</td>\n",
       "      <td>715</td>\n",
       "      <td>716</td>\n",
       "      <td>714</td>\n",
       "      <td>732</td>\n",
       "      <td>726</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33070</th>\n",
       "      <td>0.860337</td>\n",
       "      <td>0.124194</td>\n",
       "      <td>0.152559</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>258</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29702</th>\n",
       "      <td>0.619412</td>\n",
       "      <td>0.377743</td>\n",
       "      <td>0.037252</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2    0     1     2     3     4     5     6    \\\n",
       "3547   0.776554  0.054693  0.033034    0   591   694   600   495   382   287   \n",
       "34861  0.982732  0.015491  0.216774    0  1085  1238  1215  1196  1171  1154   \n",
       "18274  0.974610  0.019119  0.495488    0   877  1122  1104  1080  1051  1033   \n",
       "33070  0.860337  0.124194  0.152559    0   348   258    56     3     0     0   \n",
       "29702  0.619412  0.377743  0.037252    0    28     0     0     0     1     0   \n",
       "\n",
       "       ...  242  243  244  245  246  247  248  249  250  251  \n",
       "3547   ...   13    4    2    4    7    9    6   10    2   11  \n",
       "34861  ...  846  841  858  864  863  853  861  862  855  861  \n",
       "18274  ...  716  712  718  719  715  716  714  732  726  715  \n",
       "33070  ...    3    1    2    3    6    1    1    4    3    2  \n",
       "29702  ...    1    0    0    0    0    2    0    1    1    0  \n",
       "\n",
       "[5 rows x 255 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame (assuming it's named `df`)\n",
    "dataset = TimeSeriesDataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_dim = 3      # Number of input features\n",
    "output_dim = 1     # Predicting one value per time step\n",
    "seq_length = 252   # Number of time steps in output\n",
    "d_model = 128      # Embedding dimension for Transformer\n",
    "nhead = 4          # Number of attention heads\n",
    "num_layers = 2     # Number of Transformer layers\n",
    "dim_feedforward = 512  # Feedforward network size\n",
    "\n",
    "# Instantiate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransformerTimeSeriesModel(\n",
    "    input_dim, output_dim, seq_length, d_model, nhead, num_layers, dim_feedforward\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 4665.96337890625\n",
      "Epoch 2/40, Loss: 1847.5054931640625\n",
      "Epoch 3/40, Loss: 136.32862854003906\n",
      "Epoch 4/40, Loss: 675.1090087890625\n",
      "Epoch 5/40, Loss: 1095.3199462890625\n",
      "Epoch 6/40, Loss: 74635.546875\n",
      "Epoch 7/40, Loss: 998.234375\n",
      "Epoch 8/40, Loss: 18976.77734375\n",
      "Epoch 9/40, Loss: 519283.0625\n",
      "Epoch 10/40, Loss: 150936.609375\n",
      "Epoch 11/40, Loss: 882.1312866210938\n",
      "Epoch 12/40, Loss: 21653.677734375\n",
      "Epoch 13/40, Loss: 258784.78125\n",
      "Epoch 14/40, Loss: 202.67538452148438\n",
      "Epoch 15/40, Loss: 472110.84375\n",
      "Epoch 16/40, Loss: 224.34120178222656\n",
      "Epoch 17/40, Loss: 218.5352020263672\n",
      "Epoch 18/40, Loss: 19627.830078125\n",
      "Epoch 19/40, Loss: 700.366943359375\n",
      "Epoch 20/40, Loss: 136.22044372558594\n",
      "Epoch 21/40, Loss: 124.08040618896484\n",
      "Epoch 22/40, Loss: 105.12836456298828\n",
      "Epoch 23/40, Loss: 2429.727783203125\n",
      "Epoch 24/40, Loss: 203.0005645751953\n",
      "Epoch 25/40, Loss: 297.48150634765625\n",
      "Epoch 26/40, Loss: 20931.888671875\n",
      "Epoch 27/40, Loss: 376.426513671875\n",
      "Epoch 28/40, Loss: 653303.5\n",
      "Epoch 29/40, Loss: 585.4762573242188\n",
      "Epoch 30/40, Loss: 721462.0625\n",
      "Epoch 31/40, Loss: 1740.126708984375\n",
      "Epoch 32/40, Loss: 687656.75\n",
      "Epoch 33/40, Loss: 220628.578125\n",
      "Epoch 34/40, Loss: 1788.28369140625\n",
      "Epoch 35/40, Loss: 755.930908203125\n",
      "Epoch 36/40, Loss: 85571.03125\n",
      "Epoch 37/40, Loss: 175470.1875\n",
      "Epoch 38/40, Loss: 20269.09765625\n",
      "Epoch 39/40, Loss: 2834.490966796875\n",
      "Epoch 40/40, Loss: 94.59126281738281\n"
     ]
    }
   ],
   "source": [
    "# Optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()  # Regression loss\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 40  # Adjust based on dataset size and performance\n",
    "train_model(model, dataloader, optimizer, loss_fn, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
