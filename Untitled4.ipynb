{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b4af41-6589-48f2-9297-3b619ad06cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torch.optim import Adam\n",
    "#import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.X = torch.tensor(dataframe.iloc[:, :3].values, dtype=torch.float32)  # Input: [Batch, 3]\n",
    "        self.Y = torch.tensor(dataframe.iloc[:, 3:].values, dtype=torch.float32).unsqueeze(-1) # Output: [Batch, 255, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# Transformer Model\n",
    "class TransformerTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, seq_length, d_model, nhead, num_layers, dim_feedforward):\n",
    "        super(TransformerTimeSeriesModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    " \n",
    "        # Input Encoder (maps input to d_model size)\n",
    "        self.encoder = nn.Linear(input_dim, d_model)  # (Batch, 3) -> (Batch, d_model)\n",
    "        \n",
    "        # Project input to match the sequence length\n",
    "        self.expand_input = nn.Linear(d_model, seq_length * d_model)  # (Batch, d_model) -> (Batch, seq_length * d_model)\n",
    "        \n",
    "        # Target embedding for decoder input\n",
    "        self.target_embedding = nn.Linear(1, d_model)  # New embedding layer for target sequence\n",
    "  \n",
    "        # Positional Encoding for Time Steps\n",
    "        self.pos_encoder = PositionalEncoding(d_model, seq_length)\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Final Output Layer\n",
    "        self.output_layer = nn.Linear(d_model, output_dim)  # (Batch, 255, d_model) -> (Batch, 255, 1)\n",
    "\n",
    "    def forward(self, x, target_seq):\n",
    "        # x: Input features [Batch, 3]\n",
    "        # target_seq: Target sequence for teacher forcing [Batch, 255, 1]\n",
    "        \n",
    "        # Encode input features\n",
    "        encoded_input = self.encoder(x)  # [Batch, d_model]\n",
    "        \n",
    "        # Expand input to match sequence length\n",
    "        expanded_input = self.expand_input(encoded_input)  # [Batch, seq_length * d_model]\n",
    "        expanded_input = expanded_input.view(-1, self.seq_length, self.d_model)  # Reshape to [Batch, 255, d_model]\n",
    "        \n",
    "        # Add Positional Encoding\n",
    "        expanded_input = self.pos_encoder(expanded_input)\n",
    "        \n",
    "        # Process the target sequence through the same encoding pipeline\n",
    "  #      target_embeddings = self.encoder(target_seq)\n",
    "  #      target_embeddings = nn.Linear(1, d_model)(target_seq)  # [Batch, 255, d_model]\n",
    "        target_embeddings = self.target_embedding(target_seq)  # [Batch, 255, d_model]\n",
    "        target_embeddings = self.pos_encoder(target_embeddings)\n",
    "        \n",
    "        # Decode sequence\n",
    "        output = self.transformer_decoder(\n",
    "            tgt=target_embeddings, memory=expanded_input\n",
    "        )  # Output shape: [Batch, 255, d_model]\n",
    "        \n",
    "        # Map to output dimensions\n",
    "        predictions = self.output_layer(output)  # [Batch, 255, 1]\n",
    "        return predictions\n",
    "    \n",
    "def train_model(model, dataloader, optimizer, loss_fn, num_epochs, device):\n",
    "    loss_list = list()\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in dataloader:\n",
    "            x, y = batch  # x: [Batch, N], y: [Batch, T]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Prepare target for teacher forcing\n",
    "            target_seq = y \n",
    "            #target_seq = y[:, :-1]  # All except last time step\n",
    "            #actual = y[:, 1:]       # All except first time step\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(x, target_seq)\n",
    "            loss = loss_fn(output, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6a431f1-b682-47a6-8508-332c7d5d6788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n",
      "\n",
      "Max value is : 1451 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing data...\\n\")\n",
    "\n",
    "data_output = pd.read_csv(\"~/Desktop/TS-Clustering/SimData/epsteinCV_outputs_active.csv\", header=None)\n",
    "print(\"Max value is :\", data_output.to_numpy().max(), \"\\n\")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.data_max_ = 1600\n",
    "scaler.fit(data_output)\n",
    "data_output = scaler.transform(data_output)\n",
    "data_output = pd.DataFrame(data_output)\n",
    "\n",
    "data_input = pd.read_csv(\"~/Desktop/TS-Clustering/SimData/epsteinCV_inputs.csv\", sep=\" \", header=None)\n",
    "data = pd.concat([data_input, data_output], axis=1)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, valid_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the validation set to a new CSV file\n",
    "valid_data.to_csv(\"validation_set_epstein.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001afb1c-021c-4bb9-b450-3c813663197f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857340</td>\n",
       "      <td>0.901447</td>\n",
       "      <td>0.889731</td>\n",
       "      <td>0.885596</td>\n",
       "      <td>0.880772</td>\n",
       "      <td>0.873880</td>\n",
       "      <td>0.861475</td>\n",
       "      <td>0.858029</td>\n",
       "      <td>0.849759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782908</td>\n",
       "      <td>0.782219</td>\n",
       "      <td>0.784287</td>\n",
       "      <td>0.791178</td>\n",
       "      <td>0.787733</td>\n",
       "      <td>0.789800</td>\n",
       "      <td>0.789800</td>\n",
       "      <td>0.780841</td>\n",
       "      <td>0.782908</td>\n",
       "      <td>0.778773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50357</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921433</td>\n",
       "      <td>0.940731</td>\n",
       "      <td>0.937974</td>\n",
       "      <td>0.934528</td>\n",
       "      <td>0.933839</td>\n",
       "      <td>0.931082</td>\n",
       "      <td>0.925569</td>\n",
       "      <td>0.922812</td>\n",
       "      <td>0.920744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893177</td>\n",
       "      <td>0.893177</td>\n",
       "      <td>0.893177</td>\n",
       "      <td>0.897312</td>\n",
       "      <td>0.898001</td>\n",
       "      <td>0.897312</td>\n",
       "      <td>0.894555</td>\n",
       "      <td>0.889731</td>\n",
       "      <td>0.894555</td>\n",
       "      <td>0.894555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50358</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50359</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50360</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50361</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732598</td>\n",
       "      <td>0.816678</td>\n",
       "      <td>0.807719</td>\n",
       "      <td>0.791178</td>\n",
       "      <td>0.779462</td>\n",
       "      <td>0.768436</td>\n",
       "      <td>0.753963</td>\n",
       "      <td>0.741558</td>\n",
       "      <td>0.727085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615438</td>\n",
       "      <td>0.613370</td>\n",
       "      <td>0.613370</td>\n",
       "      <td>0.612681</td>\n",
       "      <td>0.627154</td>\n",
       "      <td>0.628532</td>\n",
       "      <td>0.618884</td>\n",
       "      <td>0.625086</td>\n",
       "      <td>0.627843</td>\n",
       "      <td>0.624397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50362 rows Ã— 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6    \\\n",
       "0      0.0  0.014473  0.000000  0.000000  0.000000  0.000689  0.000000   \n",
       "1      0.0  0.008270  0.000689  0.000000  0.000689  0.001378  0.000000   \n",
       "2      0.0  0.006892  0.001378  0.000000  0.000689  0.000000  0.000689   \n",
       "3      0.0  0.857340  0.901447  0.889731  0.885596  0.880772  0.873880   \n",
       "4      0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "50357  0.0  0.921433  0.940731  0.937974  0.934528  0.933839  0.931082   \n",
       "50358  0.0  0.004135  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "50359  0.0  0.012405  0.000000  0.000000  0.000689  0.000000  0.000000   \n",
       "50360  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "50361  0.0  0.732598  0.816678  0.807719  0.791178  0.779462  0.768436   \n",
       "\n",
       "            7         8         9    ...       242       243       244  \\\n",
       "0      0.000689  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000689  0.000000  ...  0.000689  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000  ...  0.000000  0.001378  0.000000   \n",
       "3      0.861475  0.858029  0.849759  ...  0.782908  0.782219  0.784287   \n",
       "4      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "50357  0.925569  0.922812  0.920744  ...  0.893177  0.893177  0.893177   \n",
       "50358  0.000689  0.000000  0.000000  ...  0.000689  0.000000  0.000000   \n",
       "50359  0.000000  0.000689  0.000689  ...  0.001378  0.000689  0.000000   \n",
       "50360  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "50361  0.753963  0.741558  0.727085  ...  0.615438  0.613370  0.613370   \n",
       "\n",
       "            245       246       247       248       249       250       251  \n",
       "0      0.000689  0.000689  0.000000  0.000000  0.000000  0.000689  0.000000  \n",
       "1      0.000000  0.000000  0.000689  0.000000  0.000689  0.001378  0.000689  \n",
       "2      0.000000  0.000689  0.000000  0.000000  0.000689  0.000000  0.000000  \n",
       "3      0.791178  0.787733  0.789800  0.789800  0.780841  0.782908  0.778773  \n",
       "4      0.000000  0.000000  0.000689  0.000000  0.000000  0.000000  0.000000  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "50357  0.897312  0.898001  0.897312  0.894555  0.889731  0.894555  0.894555  \n",
       "50358  0.000000  0.000689  0.000000  0.000000  0.000689  0.000000  0.000000  \n",
       "50359  0.000000  0.000689  0.000000  0.000689  0.000000  0.000000  0.000000  \n",
       "50360  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "50361  0.612681  0.627154  0.628532  0.618884  0.625086  0.627843  0.624397  \n",
       "\n",
       "[50362 rows x 252 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f27f00-8aaf-4357-ba5e-416629dcb070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e69d8-e6ec-4833-938f-421fd083e7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
